{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbfEtO7Y1YTg"
      },
      "outputs": [],
      "source": [
        "# https://github.com/huggingface/transformers/tree/master/examples/tensorflow/text-classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEmaa2YAtskt"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -r /content/requirements.txt ;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LwALv2SqHlZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "RM79aUWgpwox",
        "outputId": "3b73de5c-ca9b-4d4e-f5a4-6883c29c6efd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f3666910-4e40-4c17-ba60-9e0f6ba982c3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>language</th>\n",
              "      <th>majority_label</th>\n",
              "      <th>source</th>\n",
              "      <th>annotator1</th>\n",
              "      <th>annotator2</th>\n",
              "      <th>annotator3</th>\n",
              "      <th>translated_texts</th>\n",
              "      <th>claim</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>ഇച്ഛാശക്തിയുള്ള ഒരു ഭരണകൂടത്തിന് അസാധ്യമായൊന്ന...</td>\n",
              "      <td>ml</td>\n",
              "      <td>Yes</td>\n",
              "      <td>social media</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>There is nothing impossible for a government t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>.            *_SKY ViSiON_*        / /        ...</td>\n",
              "      <td>ml</td>\n",
              "      <td>Yes</td>\n",
              "      <td>social media</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>== sync, corrected by elderman == @elder_man =...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>+------+------+-----+------+-----+-----+------...</td>\n",
              "      <td>ml</td>\n",
              "      <td>Yes</td>\n",
              "      <td>social media</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>The-------------------------------------------...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>ബിജെപി അല്ലെങ്കിൽ യുപിയിലെ സഖ്യം... ഇവരിൽ നിന്...</td>\n",
              "      <td>ml</td>\n",
              "      <td>Yes</td>\n",
              "      <td>social media</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Bijepi or the party in Jupiter... any of them ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>.            *_SKY ViSiON_*        / /        ...</td>\n",
              "      <td>ml</td>\n",
              "      <td>Yes</td>\n",
              "      <td>social media</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>*_SKY VISION_* / /_size_**_bulance_*_bulance_*...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3666910-4e40-4c17-ba60-9e0f6ba982c3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f3666910-4e40-4c17-ba60-9e0f6ba982c3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f3666910-4e40-4c17-ba60-9e0f6ba982c3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0  ... claim\n",
              "0           0  ...     1\n",
              "1           1  ...     1\n",
              "2           2  ...     1\n",
              "3           4  ...     1\n",
              "4           5  ...     1\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "data = pd.read_csv(\"all_translated_data.csv\", encoding = \"utf-8\")\n",
        "data[\"claim\"] = data[\"majority_label\"].apply(lambda x: 1 if x == \"Yes\" else (0 if x == \"No\" else \"No_Majority\"))\n",
        "# Just use the texts with a majority label\n",
        "data = data[data.claim != \"No_Majority\"]\n",
        "data = data.reset_index(drop=True)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BubLMIGVp6t3"
      },
      "outputs": [],
      "source": [
        "# Select all languages\n",
        "data_en= data.loc[(data.language == \"en\")]\n",
        "data_hi = data.loc[(data.language == \"hi\")]\n",
        "data_bn = data.loc[(data.language == \"bn\")]\n",
        "data_ta = data.loc[(data.language == \"ta\")]\n",
        "data_ml = data.loc[(data.language == \"ml\")]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use this to make a bigger Dataframe with the selected language and the translated texts in the same language\n",
        "text_en = data_en[\"text\"].tolist()\n",
        "claim_en = data_en[\"claim\"].tolist()\n",
        "\n",
        "text_hi = data_hi[\"text\"].tolist()\n",
        "text_trans_hi = data_hi[\"translated_texts\"].tolist()\n",
        "claim_hi = data_hi[\"claim\"].tolist()\n",
        "claim_trans_hi = data_hi[\"claim\"].tolist()\n",
        "text_list_hi = text_hi + text_trans_hi + text_en\n",
        "claim_list_hi = claim_hi + claim_trans_hi + claim_en\n",
        "df_dict_hi = {\"text\": text_list_hi, \"claim\": claim_list_hi}\n",
        "df_dict_hi\n",
        "hi_trans_df = pd.DataFrame(df_dict_hi)\n",
        "\n",
        "text_ta = data_ta[\"text\"].tolist()\n",
        "text_trans_ta = data_ta[\"translated_texts\"].tolist()\n",
        "claim_ta = data_ta[\"claim\"].tolist()\n",
        "claim_trans_ta = data_ta[\"claim\"].tolist()\n",
        "text_list_ta = text_ta + text_trans_ta + text_en\n",
        "claim_list_ta = claim_ta + claim_trans_ta + claim_en\n",
        "df_dict_ta = {\"text\": text_list_ta, \"claim\": claim_list_ta}\n",
        "df_dict_ta\n",
        "ta_trans_df = pd.DataFrame(df_dict_ta)\n",
        "\n",
        "text_ml = data_ml[\"text\"].tolist()\n",
        "text_trans_ml = data_ml[\"translated_texts\"].tolist()\n",
        "claim_ml = data_ml[\"claim\"].tolist()\n",
        "claim_trans_ml = data_ml[\"claim\"].tolist()\n",
        "text_list_ml = text_ml + text_trans_ml + text_en\n",
        "claim_list_ml = claim_ml + claim_trans_ml + claim_en\n",
        "df_dict_ml = {\"text\": text_list_ml, \"claim\": claim_list_ml}\n",
        "df_dict_ml\n",
        "ml_trans_df = pd.DataFrame(df_dict_ml)\n",
        "\n",
        "text_bn = data_bn[\"text\"].tolist()\n",
        "text_trans_bn = data_bn[\"translated_texts\"].tolist()\n",
        "claim_bn = data_bn[\"claim\"].tolist()\n",
        "claim_trans_bn = data_bn[\"claim\"].tolist()\n",
        "text_list_bn = text_bn + text_trans_bn + text_en\n",
        "claim_list_bn = claim_bn + claim_trans_bn + claim_en\n",
        "df_dict_bn = {\"text\": text_list_bn, \"claim\": claim_list_bn}\n",
        "df_dict_bn\n",
        "bn_trans_df = pd.DataFrame(df_dict_bn)"
      ],
      "metadata": {
        "id": "ceZyhfeQTvK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bn_trans_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "1LjoPxsQYyI7",
        "outputId": "924a07eb-73e3-489d-c81c-0ec5af901e0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-81396310-d926-41d9-b111-14dcffb655fd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>claim</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>সার্জিক্যাল স্ট্রাইকের কৃতিত্ব যদি সরকার নিতে ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>*www.bahrswb.org: বিজেপির ‘জয় শ্রীরাম’ নিয়ে এ ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>তোমার জন্য স্পেশাল কিছু পাঠিয়েছি তাড়াতাড়ি ন...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ইষ্টের আসনে অন্য কোন ফটো রাখলে ক্ষতি কি ?.  \"আ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>আসন্ন সপ্তদশ লোকসভা নির্বাচনে , কাঁথি লোকসভা ক...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2762</th>\n",
              "      <td>**Prayer for the day* \"Lord Jesus, faith in yo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2763</th>\n",
              "      <td>Dear  Sir,\\nI just want to drop in a personal ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2764</th>\n",
              "      <td>Fact-check: Moscow metro allows free rides to ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2765</th>\n",
              "      <td>Says as a result of the national health care r...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2766</th>\n",
              "      <td>'Less than half of the poorest American househ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2767 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81396310-d926-41d9-b111-14dcffb655fd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-81396310-d926-41d9-b111-14dcffb655fd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-81396310-d926-41d9-b111-14dcffb655fd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   text  claim\n",
              "0     সার্জিক্যাল স্ট্রাইকের কৃতিত্ব যদি সরকার নিতে ...      1\n",
              "1     *www.bahrswb.org: বিজেপির ‘জয় শ্রীরাম’ নিয়ে এ ...      1\n",
              "2     তোমার জন্য স্পেশাল কিছু পাঠিয়েছি তাড়াতাড়ি ন...      0\n",
              "3     ইষ্টের আসনে অন্য কোন ফটো রাখলে ক্ষতি কি ?.  \"আ...      0\n",
              "4     আসন্ন সপ্তদশ লোকসভা নির্বাচনে , কাঁথি লোকসভা ক...      1\n",
              "...                                                 ...    ...\n",
              "2762  **Prayer for the day* \"Lord Jesus, faith in yo...      0\n",
              "2763  Dear  Sir,\\nI just want to drop in a personal ...      0\n",
              "2764  Fact-check: Moscow metro allows free rides to ...      1\n",
              "2765  Says as a result of the national health care r...      1\n",
              "2766  'Less than half of the poorest American househ...      1\n",
              "\n",
              "[2767 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsW1v8rovCfy"
      },
      "outputs": [],
      "source": [
        "# Create Train, Test, Validate for every language\n",
        "#data_en = data_en[[\"text\", \"claim\"]]\n",
        "data_hi = hi_trans_df[[\"text\", \"claim\"]]\n",
        "data_ml = ml_trans_df[[\"text\", \"claim\"]]\n",
        "data_ta = ta_trans_df[[\"text\", \"claim\"]]\n",
        "data_bn = bn_trans_df[[\"text\", \"claim\"]]\n",
        "\n",
        "data_en = data_en.rename({'text': 'sentence1', 'claim': 'label'}, axis='columns')\n",
        "data_hi = data_hi.rename({'text': 'sentence1', 'claim': 'label'}, axis='columns')\n",
        "data_ml = data_ml.rename({'text': 'sentence1', 'claim': 'label'}, axis='columns')\n",
        "data_ta = data_ta.rename({'text': 'sentence1', 'claim': 'label'}, axis='columns')\n",
        "data_bn = data_bn.rename({'text': 'sentence1', 'claim': 'label'}, axis='columns')\n",
        "\n",
        "#set seed\n",
        "np.random.seed(0)\n",
        "train_en, validate_en, test_en = np.split(data_en.sample(frac=1), [int(.6*len(data_en)), int(.8*len(data_en))])\n",
        "train_en.to_csv(\"train_en.csv\")\n",
        "validate_en.to_csv(\"validate_en.csv\")\n",
        "test_en.to_csv(\"test_en.csv\")\n",
        "\n",
        "#set seed\n",
        "np.random.seed(0)\n",
        "train_hi, validate_hi, test_hi = np.split(data_hi.sample(frac=1), [int(.6*len(data_hi)), int(.8*len(data_hi))])\n",
        "train_hi.to_csv(\"train_hi.csv\")\n",
        "validate_hi.to_csv(\"validate_hi.csv\")\n",
        "test_hi.to_csv(\"test_hi.csv\")\n",
        "\n",
        "#set seed\n",
        "np.random.seed(0)\n",
        "train_ml, validate_ml, test_ml = np.split(data_ml.sample(frac=1), [int(.6*len(data_ml)), int(.8*len(data_ml))])\n",
        "train_ml.to_csv(\"train_ml.csv\")\n",
        "validate_ml.to_csv(\"validate_ml.csv\")\n",
        "test_ml.to_csv(\"test_ml.csv\")\n",
        "\n",
        "#set seed\n",
        "np.random.seed(0)\n",
        "train_ta, validate_ta, test_ta = np.split(data_ta.sample(frac=1), [int(.6*len(data_ta)), int(.8*len(data_ta))])\n",
        "train_ta.to_csv(\"train_ta.csv\")\n",
        "validate_ta.to_csv(\"validate_ta.csv\")\n",
        "test_ta.to_csv(\"test_ta.csv\")\n",
        "\n",
        "#set seed\n",
        "np.random.seed(0)\n",
        "train_bn, validate_bn, test_bn = np.split(data_bn.sample(frac=1), [int(.6*len(data_bn)), int(.8*len(data_bn))])\n",
        "train_bn.to_csv(\"train_bn.csv\")\n",
        "validate_bn.to_csv(\"validate_bn.csv\")\n",
        "test_bn.to_csv(\"test_bn.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9CdNND5u4u5",
        "outputId": "94cc1885-972d-43a6-e3a2-c3b958c1cf77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1717\n",
            "573\n",
            "573\n"
          ]
        }
      ],
      "source": [
        "print(len(train_ml))\n",
        "print(len(test_ml))\n",
        "print(len(validate_ml))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cf4fCk6jzh6E",
        "outputId": "f4a44369-2bc1-4c22-93e7-0a7abd6a5a45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a28c6501-1fbe-4ee4-ac6b-a3e0c0f6c3a1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence1</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>നരേന്ദ്ര മോദിയെ തോൽപ്പിക്കാൻ രാഹുൽ ഗാന്ധി വയനാ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>747</th>\n",
              "      <td>ബി ജെ പി വിരുദ്ധ വിശാല സഖ്യം സർക്കാർ രൂപീകരിക്...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2624</th>\n",
              "      <td>Fareportal India PVT.LTD terminated 500+ emplo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>753</th>\n",
              "      <td>*അക്രമ രാഷ്ട്രീയത്തിലൂടെ എല്ലാകാലത്തും അധികാരത...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462</th>\n",
              "      <td>സംഭവം ഞാനൊരു കമ്മ്യൂണിസ്റ്റ് കാരനാണെങ്കിലും പറ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a28c6501-1fbe-4ee4-ac6b-a3e0c0f6c3a1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a28c6501-1fbe-4ee4-ac6b-a3e0c0f6c3a1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a28c6501-1fbe-4ee4-ac6b-a3e0c0f6c3a1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                              sentence1  label\n",
              "46    നരേന്ദ്ര മോദിയെ തോൽപ്പിക്കാൻ രാഹുൽ ഗാന്ധി വയനാ...      1\n",
              "747   ബി ജെ പി വിരുദ്ധ വിശാല സഖ്യം സർക്കാർ രൂപീകരിക്...      1\n",
              "2624  Fareportal India PVT.LTD terminated 500+ emplo...      1\n",
              "753   *അക്രമ രാഷ്ട്രീയത്തിലൂടെ എല്ലാകാലത്തും അധികാരത...      1\n",
              "462   സംഭവം ഞാനൊരു കമ്മ്യൂണിസ്റ്റ് കാരനാണെങ്കിലും പറ...      1"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "test_ml[:5]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python text_class.py \\\n",
        "--model_name_or_path meedan/indian-xlm-r \\\n",
        "--train_file train_bn.csv \\\n",
        "--validation_file validate_bn.csv \\\n",
        "--output_dir output_bn/ \\\n",
        "--test_file test_bn.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZPL0i6QcZMn",
        "outputId": "a271e766-3f07-4744-e015-111c0fa8add7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "02/14/2022 14:25:25 - INFO - __main__ - Training/evaluation parameters TFTrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=IntervalStrategy.NO,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "gcp_project=None,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=-1,\n",
            "log_level_replica=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=output_bn/runs/Feb14_14-25-25_c73ea1f5f077,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=OptimizerNames.ADAMW_HF,\n",
            "output_dir=output_bn/,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "poly_power=1.0,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=output_bn/,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=IntervalStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_name=None,\n",
            "tpu_num_cores=None,\n",
            "tpu_zone=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xla=False,\n",
            "xpu_backend=None,\n",
            ")\n",
            "02/14/2022 14:25:25 - INFO - __main__ - Loading a local file for train: train_bn.csv\n",
            "02/14/2022 14:25:25 - INFO - __main__ - Loading a local file for validation: validate_bn.csv\n",
            "02/14/2022 14:25:25 - INFO - __main__ - Loading a local file for test: test_bn.csv\n",
            "02/14/2022 14:25:26 - WARNING - datasets.builder - Using custom data configuration default-9e9eb5c4d3029abc\n",
            "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-9e9eb5c4d3029abc/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e...\n",
            "100% 3/3 [00:00<00:00, 8689.86it/s]\n",
            "100% 3/3 [00:00<00:00, 1185.39it/s]\n",
            "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-9e9eb5c4d3029abc/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e. Subsequent calls will reuse this data.\n",
            "100% 3/3 [00:00<00:00, 864.45it/s]\n",
            "Downloading: 100% 506/506 [00:00<00:00, 413kB/s]\n",
            "Downloading: 100% 25.0/25.0 [00:00<00:00, 21.7kB/s]\n",
            "Downloading: 100% 4.83M/4.83M [00:01<00:00, 2.77MB/s]\n",
            "Downloading: 100% 150/150 [00:00<00:00, 111kB/s]\n",
            "100% 2/2 [00:00<00:00,  6.35ba/s]\n",
            "100% 1/1 [00:00<00:00, 10.70ba/s]\n",
            "100% 1/1 [00:00<00:00, 10.92ba/s]\n",
            "2022-02-14 14:25:52.373642: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "404 Client Error: Entry Not Found for url: https://huggingface.co/meedan/indian-xlm-r/resolve/main/tf_model.h5\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/modeling_tf_utils.py\", line 1585, in from_pretrained\n",
            "    user_agent=user_agent,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/file_utils.py\", line 1854, in cached_path\n",
            "    local_files_only=local_files_only,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/file_utils.py\", line 2050, in get_from_cache\n",
            "    _raise_for_status(r)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/file_utils.py\", line 1973, in _raise_for_status\n",
            "    raise EntryNotFoundError(f\"404 Client Error: Entry Not Found for url: {request.url}\")\n",
            "transformers.file_utils.EntryNotFoundError: 404 Client Error: Entry Not Found for url: https://huggingface.co/meedan/indian-xlm-r/resolve/main/tf_model.h5\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"text_class.py\", line 555, in <module>\n",
            "    main()\n",
            "  File \"text_class.py\", line 440, in main\n",
            "    use_auth_token=True if model_args.use_auth_token else None,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/auto/auto_factory.py\", line 447, in from_pretrained\n",
            "    return model_class.from_pretrained(pretrained_model_name_or_path, *model_args, config=config, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/modeling_tf_utils.py\", line 1614, in from_pretrained\n",
            "    f\"{pretrained_model_name_or_path} does not appear to have a file named {TF2_WEIGHTS_NAME} \"\n",
            "OSError: meedan/indian-xlm-r does not appear to have a file named tf_model.h5 but there is a file for PyTorch weights. Use `from_pt=True` to load this model from those weights.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python text_class.py \\\n",
        "--model_name_or_path google/muril-base-cased \\\n",
        "--train_file train_hi.csv \\\n",
        "--validation_file validate_hi.csv \\\n",
        "--output_dir output_hi/ \\\n",
        "--test_file test_hi.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuvOJ1m0cZ-o",
        "outputId": "9c0641c1-81d3-47df-9908-560a91c8ef8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "01/25/2022 16:49:08 - INFO - __main__ - Training/evaluation parameters TFTrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=IntervalStrategy.NO,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "gcp_project=None,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=-1,\n",
            "log_level_replica=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=output_hi/runs/Jan25_16-49-08_af253d0139ec,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "output_dir=output_hi/,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "poly_power=1.0,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=output_hi/,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=IntervalStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_name=None,\n",
            "tpu_num_cores=None,\n",
            "tpu_zone=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xla=False,\n",
            "xpu_backend=None,\n",
            ")\n",
            "01/25/2022 16:49:08 - INFO - __main__ - Loading a local file for train: train_hi.csv\n",
            "01/25/2022 16:49:08 - INFO - __main__ - Loading a local file for validation: validate_hi.csv\n",
            "01/25/2022 16:49:08 - INFO - __main__ - Loading a local file for test: test_hi.csv\n",
            "01/25/2022 16:49:08 - WARNING - datasets.builder - Using custom data configuration default-f8e55956562801eb\n",
            "01/25/2022 16:49:08 - WARNING - datasets.builder - Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-f8e55956562801eb/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e)\n",
            "100% 3/3 [00:00<00:00, 389.41it/s]\n",
            "100% 2/2 [00:00<00:00, 10.53ba/s]\n",
            "100% 1/1 [00:00<00:00, 15.65ba/s]\n",
            "100% 1/1 [00:00<00:00, 16.30ba/s]\n",
            "2022-01-25 16:49:15.733839: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at google/muril-base-cased and are newly initialized: ['classifier', 'bert/pooler/dense/kernel:0', 'bert/pooler/dense/bias:0']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "2022-01-25 16:49:22.267159: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:766] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_4\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "input: \"Placeholder/_3\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_VARIANT\n",
            "      type: DT_VARIANT\n",
            "      type: DT_VARIANT\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 1600\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\024TensorSliceDataset:0\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "Epoch 1/3\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6718 - accuracy: 0.5838 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+002022-01-25 16:50:35.404207: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:766] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_4\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "input: \"Placeholder/_3\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_VARIANT\n",
            "      type: DT_VARIANT\n",
            "      type: DT_VARIANT\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 533\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\024TensorSliceDataset:4\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "2022-01-25 16:50:42.443696: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 606059520 exceeds 10% of free system memory.\n",
            "200/200 [==============================] - 85s 318ms/step - loss: 0.6718 - accuracy: 0.5838 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6917 - val_accuracy: 0.5385 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 2/3\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6916 - accuracy: 0.5150 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+002022-01-25 16:51:44.992001: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 606059520 exceeds 10% of free system memory.\n",
            "200/200 [==============================] - 62s 310ms/step - loss: 0.6916 - accuracy: 0.5150 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6909 - val_accuracy: 0.5403 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 3/3\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6939 - accuracy: 0.4744 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+002022-01-25 16:52:46.937792: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 606059520 exceeds 10% of free system memory.\n",
            "200/200 [==============================] - 62s 308ms/step - loss: 0.6939 - accuracy: 0.4744 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6943 - val_accuracy: 0.4597 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "01/25/2022 16:52:50 - INFO - __main__ - Doing predictions on test dataset...\n",
            "2022-01-25 16:52:51.052358: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:766] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_4\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "input: \"Placeholder/_3\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_VARIANT\n",
            "      type: DT_VARIANT\n",
            "      type: DT_VARIANT\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 534\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\024TensorSliceDataset:7\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "01/25/2022 16:52:58 - INFO - __main__ - Wrote predictions to output_hi/test_results.txt!\n",
            "Computing prediction loss on test labels...\n",
            "Test loss: 0.6917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python text_class.py \\\n",
        "--model_name_or_path google/muril-base-cased \\\n",
        "--train_file train_ml.csv \\\n",
        "--validation_file validate_ml.csv \\\n",
        "--output_dir output_ml/ \\\n",
        "--test_file test_ml.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsNybEa7cadI",
        "outputId": "bfd462b5-7a66-4d99-afad-00b74762a93a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "01/25/2022 16:53:06 - INFO - __main__ - Training/evaluation parameters TFTrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=IntervalStrategy.NO,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "gcp_project=None,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=-1,\n",
            "log_level_replica=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=output_ml/runs/Jan25_16-53-05_af253d0139ec,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "output_dir=output_ml/,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "poly_power=1.0,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=output_ml/,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=IntervalStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_name=None,\n",
            "tpu_num_cores=None,\n",
            "tpu_zone=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xla=False,\n",
            "xpu_backend=None,\n",
            ")\n",
            "01/25/2022 16:53:06 - INFO - __main__ - Loading a local file for train: train_ml.csv\n",
            "01/25/2022 16:53:06 - INFO - __main__ - Loading a local file for validation: validate_ml.csv\n",
            "01/25/2022 16:53:06 - INFO - __main__ - Loading a local file for test: test_ml.csv\n",
            "01/25/2022 16:53:06 - WARNING - datasets.builder - Using custom data configuration default-4f40bd8d24a2ee7d\n",
            "01/25/2022 16:53:06 - WARNING - datasets.builder - Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-4f40bd8d24a2ee7d/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e)\n",
            "100% 3/3 [00:00<00:00, 286.71it/s]\n",
            "100% 2/2 [00:00<00:00,  6.71ba/s]\n",
            "100% 1/1 [00:00<00:00,  9.73ba/s]\n",
            "100% 1/1 [00:00<00:00,  9.80ba/s]\n",
            "2022-01-25 16:53:13.189053: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at google/muril-base-cased and are newly initialized: ['classifier', 'bert/pooler/dense/kernel:0', 'bert/pooler/dense/bias:0']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "2022-01-25 16:53:16.666897: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:766] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_4\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "input: \"Placeholder/_3\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_VARIANT\n",
            "      type: DT_VARIANT\n",
            "      type: DT_VARIANT\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 1717\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\024TensorSliceDataset:0\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "Epoch 1/3\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5884 - accuracy: 0.7056 - f1_m: 0.3580 - precision_m: 0.4004 - recall_m: 0.35552022-01-25 16:54:38.169909: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:766] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_4\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "input: \"Placeholder/_3\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_VARIANT\n",
            "      type: DT_VARIANT\n",
            "      type: DT_VARIANT\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 573\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\024TensorSliceDataset:4\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "2022-01-25 16:54:46.159371: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 606059520 exceeds 10% of free system memory.\n",
            "214/214 [==============================] - 94s 342ms/step - loss: 0.5884 - accuracy: 0.7056 - f1_m: 0.3580 - precision_m: 0.4004 - recall_m: 0.3555 - val_loss: 0.5423 - val_accuracy: 0.6475 - val_f1_m: 0.6058 - val_precision_m: 0.9028 - val_recall_m: 0.4844\n",
            "Epoch 2/3\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5021 - accuracy: 0.7208 - f1_m: 0.7149 - precision_m: 0.8964 - recall_m: 0.65132022-01-25 16:55:56.968686: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 606059520 exceeds 10% of free system memory.\n",
            "214/214 [==============================] - 70s 326ms/step - loss: 0.5021 - accuracy: 0.7208 - f1_m: 0.7149 - precision_m: 0.8964 - recall_m: 0.6513 - val_loss: 0.4765 - val_accuracy: 0.6841 - val_f1_m: 0.7851 - val_precision_m: 0.9158 - val_recall_m: 0.7165\n",
            "Epoch 3/3\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5028 - accuracy: 0.6951 - f1_m: 0.6440 - precision_m: 0.8618 - recall_m: 0.56012022-01-25 16:57:07.696114: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 606059520 exceeds 10% of free system memory.\n",
            "214/214 [==============================] - 71s 330ms/step - loss: 0.5028 - accuracy: 0.6951 - f1_m: 0.6440 - precision_m: 0.8618 - recall_m: 0.5601 - val_loss: 0.6160 - val_accuracy: 0.8150 - val_f1_m: 0.8642 - val_precision_m: 0.8094 - val_recall_m: 0.9555\n",
            "01/25/2022 16:57:11 - INFO - __main__ - Doing predictions on test dataset...\n",
            "2022-01-25 16:57:11.787780: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:766] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_4\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "input: \"Placeholder/_3\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_VARIANT\n",
            "      type: DT_VARIANT\n",
            "      type: DT_VARIANT\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 573\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\024TensorSliceDataset:7\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "01/25/2022 16:57:19 - INFO - __main__ - Wrote predictions to output_ml/test_results.txt!\n",
            "Computing prediction loss on test labels...\n",
            "Test loss: 0.5729\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python text_class.py \\\n",
        "--model_name_or_path google/muril-base-cased \\\n",
        "--train_file train_ta.csv \\\n",
        "--validation_file validate_ta.csv \\\n",
        "--output_dir output_ta/ \\\n",
        "--test_file test_ta.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ivv2TJrHca7Z",
        "outputId": "c146969e-a3a5-4470-9ea5-cfca092999cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "01/25/2022 16:57:27 - INFO - __main__ - Training/evaluation parameters TFTrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=IntervalStrategy.NO,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "gcp_project=None,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=-1,\n",
            "log_level_replica=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=output_ta/runs/Jan25_16-57-27_af253d0139ec,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "output_dir=output_ta/,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "poly_power=1.0,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=output_ta/,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=IntervalStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_name=None,\n",
            "tpu_num_cores=None,\n",
            "tpu_zone=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xla=False,\n",
            "xpu_backend=None,\n",
            ")\n",
            "01/25/2022 16:57:27 - INFO - __main__ - Loading a local file for train: train_ta.csv\n",
            "01/25/2022 16:57:27 - INFO - __main__ - Loading a local file for validation: validate_ta.csv\n",
            "01/25/2022 16:57:27 - INFO - __main__ - Loading a local file for test: test_ta.csv\n",
            "01/25/2022 16:57:27 - WARNING - datasets.builder - Using custom data configuration default-effdf8fef3ade776\n",
            "01/25/2022 16:57:27 - WARNING - datasets.builder - Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-effdf8fef3ade776/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e)\n",
            "100% 3/3 [00:00<00:00, 468.04it/s]\n",
            "100% 1/1 [00:00<00:00,  8.71ba/s]\n",
            "100% 1/1 [00:00<00:00, 25.21ba/s]\n",
            "100% 1/1 [00:00<00:00, 23.38ba/s]\n",
            "2022-01-25 16:57:34.557250: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at google/muril-base-cased and are newly initialized: ['classifier', 'bert/pooler/dense/bias:0', 'bert/pooler/dense/kernel:0']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "2022-01-25 16:57:37.338415: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:766] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_4\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "input: \"Placeholder/_3\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_VARIANT\n",
            "      type: DT_VARIANT\n",
            "      type: DT_VARIANT\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 949\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\024TensorSliceDataset:0\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "Epoch 1/3\n",
            "118/118 [==============================] - ETA: 0s - loss: 0.6190 - accuracy: 0.7129 - f1_m: 0.0721 - precision_m: 0.0825 - recall_m: 0.07072022-01-25 16:58:29.384791: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:766] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_4\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "input: \"Placeholder/_3\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_VARIANT\n",
            "      type: DT_VARIANT\n",
            "      type: DT_VARIANT\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 317\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\024TensorSliceDataset:4\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "2022-01-25 16:58:34.937214: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 606059520 exceeds 10% of free system memory.\n",
            "118/118 [==============================] - 62s 345ms/step - loss: 0.6190 - accuracy: 0.7129 - f1_m: 0.0721 - precision_m: 0.0825 - recall_m: 0.0707 - val_loss: 0.4887 - val_accuracy: 0.8170 - val_f1_m: 0.6327 - val_precision_m: 0.9158 - val_recall_m: 0.5102\n",
            "Epoch 2/3\n",
            "118/118 [==============================] - ETA: 0s - loss: 0.4055 - accuracy: 0.8517 - f1_m: 0.6915 - precision_m: 0.6191 - recall_m: 0.87182022-01-25 16:59:13.326763: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 606059520 exceeds 10% of free system memory.\n",
            "118/118 [==============================] - 38s 321ms/step - loss: 0.4055 - accuracy: 0.8517 - f1_m: 0.6915 - precision_m: 0.6191 - recall_m: 0.8718 - val_loss: 0.3847 - val_accuracy: 0.8391 - val_f1_m: 0.7147 - val_precision_m: 0.6033 - val_recall_m: 0.9280\n",
            "Epoch 3/3\n",
            "118/118 [==============================] - ETA: 0s - loss: 0.2554 - accuracy: 0.9153 - f1_m: 0.7117 - precision_m: 0.5810 - recall_m: 0.97652022-01-25 16:59:51.273362: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 606059520 exceeds 10% of free system memory.\n",
            "118/118 [==============================] - 38s 320ms/step - loss: 0.2554 - accuracy: 0.9153 - f1_m: 0.7117 - precision_m: 0.5810 - recall_m: 0.9765 - val_loss: 0.3856 - val_accuracy: 0.8612 - val_f1_m: 0.6944 - val_precision_m: 0.5869 - val_recall_m: 0.9016\n",
            "01/25/2022 16:59:55 - INFO - __main__ - Doing predictions on test dataset...\n",
            "2022-01-25 16:59:55.255526: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:766] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_4\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "input: \"Placeholder/_3\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_VARIANT\n",
            "      type: DT_VARIANT\n",
            "      type: DT_VARIANT\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 317\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\024TensorSliceDataset:7\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "01/25/2022 17:00:00 - INFO - __main__ - Wrote predictions to output_ta/test_results.txt!\n",
            "Computing prediction loss on test labels...\n",
            "Test loss: 0.3038\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_hi_res = pd.read_csv('output_hi/test_results.txt', sep=\"\\t\")\n",
        "test_hi = pd.read_csv('test_hi.csv')\n",
        "test_hi_res = test_hi_res.prediction\n",
        "test_hi.label\n",
        "\n",
        "#print(\"HI: Classification report: \\n\", (classification_report(test_hi.label, test_hi_res)))\n",
        "print(\"HI: F1 micro averaging:\",(f1_score(test_hi.label, test_hi_res, average='micro',labels=np.unique(test_hi_res))))\n",
        "print(\"HI: F1 macro averaging:\",(f1_score(test_hi.label, test_hi_res, average='macro',labels=np.unique(test_hi_res))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjVmsl2QiN95",
        "outputId": "a5d1fc65-0b61-41f1-9bb6-ed8ae789d8c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HI: F1 micro averaging: 0.7163461538461539\n",
            "HI: F1 macro averaging: 0.7163461538461539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ml_res = pd.read_csv('output_ml/test_results.txt', sep=\"\\t\")\n",
        "test_ml = pd.read_csv('test_ml.csv')\n",
        "test_ml_res = test_ml_res.prediction\n",
        "test_ml.label\n",
        "\n",
        "#print(\"ML: Classification report: \\n\", (classification_report(test_ml.label, test_ml_res)))\n",
        "print(\"ML: F1 micro averaging:\",(f1_score(test_ml.label, test_ml_res, average='micro', labels=np.unique(test_ml_res))))\n",
        "print(\"ML: F1 macro averaging:\",(f1_score(test_ml.label, test_ml_res, average='macro', labels=np.unique(test_ml_res))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOVnx7g1i4X7",
        "outputId": "e41019e6-5bd1-47c1-9c87-4cb1acc6582a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ML: F1 micro averaging: 0.8342059336823734\n",
            "ML: F1 macro averaging: 0.7680586979586097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ta_res = pd.read_csv('output_ta/test_results.txt', sep=\"\\t\")\n",
        "test_ta = pd.read_csv('test_ta.csv')\n",
        "test_ta_res = test_ta_res.prediction\n",
        "test_ta.label\n",
        "\n",
        "print(\"TA: Classification report: \\n\", (classification_report(test_ta.label, test_ta_res)))\n",
        "print(\"TA: F1 micro averaging:\",(f1_score(test_ta.label, test_ta_res, average='micro')))\n",
        "print(\"TA: F1 macro averaging:\",(f1_score(test_ta.label, test_ta_res, average='macro')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6_dncn5jIUR",
        "outputId": "fdfe01e8-dbea-4b1f-e46e-d47168564486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TA: Classification report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.90      0.85       116\n",
            "           1       0.94      0.87      0.90       201\n",
            "\n",
            "    accuracy                           0.88       317\n",
            "   macro avg       0.87      0.88      0.87       317\n",
            "weighted avg       0.89      0.88      0.88       317\n",
            "\n",
            "TA: F1 micro averaging: 0.8801261829652995\n",
            "TA: F1 macro averaging: 0.873795155477328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_bn_res = pd.read_csv('output_bn/test_results.txt', sep=\"\\t\")\n",
        "test_bn = pd.read_csv('test_bn.csv')\n",
        "test_bn_res = test_bn_res.prediction\n",
        "test_bn.label\n",
        "\n",
        "#print(\"BN: Classification report: \\n\", (classification_report(test_bn.label, test_bn_res)))\n",
        "print(\"BN: F1 micro averaging:\",(f1_score(test_bn.label, test_bn_res, average='micro', labels=np.unique(test_bn_res))))\n",
        "print(\"BN: F1 macro averaging:\",(f1_score(test_bn.label, test_bn_res, average='macro', labels=np.unique(test_bn_res))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXnPAjNzjfWC",
        "outputId": "2c8d010a-0a56-4adb-e9fd-a4569e59a581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BN: F1 micro averaging: 0.7235023041474653\n",
            "BN: F1 macro averaging: 0.7235023041474653\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Approach2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}